{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE072_ParthMakwana_Lab8_Part2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise: Try this on full spam.csv file and bigram matching instead of unigram matching**"
      ],
      "metadata": {
        "id": "YltRDOFWSQxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XbJ7bwWiSEkF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\",\n",
        "\"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\",\n",
        "\"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
        "\"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\",\n",
        "\"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
        "\"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\",\n",
        "\"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\",\n",
        "\"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\",\n",
        "\"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\",\n",
        "\"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\",\n",
        "\"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\",\n",
        "\"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\",\n",
        "\"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\",\n",
        "\"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\",\n",
        "\"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "\"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\",\n",
        "\"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\",\n",
        "\"yourselves\"]"
      ],
      "metadata": {
        "id": "Y4N14YcKSwWO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NHs7rM9SyOd",
        "outputId": "87c82a3f-f5bc-4065-8d0b-cd5ac87fd171"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = pd.read_csv('/content/drive/MyDrive/Data/SPAM2.csv') \n",
        "datasets[\"v1\"]=np.where(datasets[\"v1\"]=='spam',1,0)\n",
        "print(\"\\nData :\\n\",datasets.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXwxE0_dS2FQ",
        "outputId": "b0c655f6-9d67-4d31-8759-1d15a69c6bdc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data :\n",
            "     v1                                                 v2\n",
            "0    0  Go until jurong point, crazy.. Available only ...\n",
            "1    0                      Ok lar... Joking wif u oni...\n",
            "2    1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    0  U dun say so early hor... U c already then say...\n",
            "4    0  Nah I don't think he goes to usf, he lives aro...\n",
            "5    1  FreeMsg Hey there darling it's been 3 week's n...\n",
            "6    0  Even my brother is not like to speak with me. ...\n",
            "7    0  As per your request 'Melle Melle (Oru Minnamin...\n",
            "8    1  WINNER!! As a valued network customer you have...\n",
            "9    1  Had your mobile 11 months or more? U R entitle...\n",
            "10   0  I'm gonna be home soon and i don't want to tal...\n",
            "11   1  SIX chances to win CASH! From 100 to 20,000 po...\n",
            "12   1  URGENT! You have won a 1 week FREE membership ...\n",
            "13   0  I've been searching for the right words to tha...\n",
            "14   0                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
            "15   1  XXXMobileMovieClub: To use your credit, click ...\n",
            "16   0                         Oh k...i'm watching here:)\n",
            "17   0  Eh u remember how 2 spell his name... Yes i di...\n",
            "18   0  Fine if that��s the way u feel. That��s the wa...\n",
            "19   1  England v Macedonia - dont miss the goals/team...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasets[\"v2\"], datasets[\"v1\"],random_state=72)\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEmWiyHgTS2A",
        "outputId": "db40d300-9481-4ea4-8c19-e19788b65a70"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1393,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CountVectorizer**"
      ],
      "metadata": {
        "id": "NMAJAuP5Td0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform Count Vectorization on training data**"
      ],
      "metadata": {
        "id": "fIwR46OoTgmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range = (2, 2),stop_words=stopwords)\n",
        "vectorizer.fit(X_train)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "print(X_train_vectorized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HPILYFTXRt",
        "outputId": "8a2fe1d6-62b1-4abf-9647-1e0c5b36e765"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply the Naive Bayes on Vectorized data.**"
      ],
      "metadata": {
        "id": "Ct4iWN6ITuDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb=MultinomialNB()\n",
        "nb.fit(X_train_vectorized,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCHA65eoTumb",
        "outputId": "c73c17fa-1571-4e21-e94d-40eac3e6cbe0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = nb.predict(vectorizer.transform(X_test))\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"Precision: \", precision_score(y_test, predictions))\n",
        "print(\"Recall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd2R3961T9rh",
        "outputId": "0a966e42-b31f-412d-e311-eb1dd25a6e2d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9806173725771715\n",
            "Precision:  0.9939759036144579\n",
            "Recall:  0.8638743455497382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply the Decision Tree Classifier on Vectorized data.**"
      ],
      "metadata": {
        "id": "Qa0r4oKiUEPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtcf = DecisionTreeClassifier()\n",
        "dtcf.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YiSxOUdUCg7",
        "outputId": "c4a1d276-f275-43e4-cd7d-37c254abcfcb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = dtcf.predict(vectorizer.transform(X_test))\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"Precision: \", precision_score(y_test, predictions))\n",
        "print(\"Recall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpMQ-1M_USgC",
        "outputId": "14e1ee0c-e5ce-48e1-f035-ff593574a871"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9691313711414213\n",
            "Precision:  1.0\n",
            "Recall:  0.774869109947644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TFIDF Vectorizer**"
      ],
      "metadata": {
        "id": "zcH8pbeeUU89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform IFIDF Vectorization on training data.**"
      ],
      "metadata": {
        "id": "WLjp7aTgUXIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range = (2, 2),stop_words = stopwords)\n",
        "vectorizer.fit(X_train)\n",
        "X_train_tfidf_vectorized = vectorizer.transform(X_train)\n",
        "print(X_train_tfidf_vectorized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChE8qS8RUaUx",
        "outputId": "644767a1-0a62-4f4a-f742-46e4a561cd28"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply the Naive Bayes on IFIDF Vectorized data.**"
      ],
      "metadata": {
        "id": "KoYXsVOXUhJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_tfidf_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDIq55PSUd6E",
        "outputId": "bb6c278c-e57c-45c0-d9dd-1b2354f92ff1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = nb.predict(vectorizer.transform(X_test))\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"Precision: \", precision_score(y_test, predictions))\n",
        "print(\"Recall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTTGDZTKUl2i",
        "outputId": "1bb9af06-224c-4392-f9b0-c70d2ef85980"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9411342426417804\n",
            "Precision:  1.0\n",
            "Recall:  0.5706806282722513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply the Decision Tree Classifier on IFIDF Vectorized data.**"
      ],
      "metadata": {
        "id": "Whi8nIc_UsZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtcf = DecisionTreeClassifier()\n",
        "dtcf.fit(X_train_tfidf_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG_ZZFBOUpVM",
        "outputId": "6d7e58fd-24cc-4d28-b509-f177d2a0767e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = dtcf.predict(vectorizer.transform(X_test))\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"Precision: \", precision_score(y_test, predictions))\n",
        "print(\"Recall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fwT6SsQU9Y_",
        "outputId": "177cc754-4bea-4bd6-add5-ac50f612343a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9676956209619526\n",
            "Precision:  0.9932432432432432\n",
            "Recall:  0.7696335078534031\n"
          ]
        }
      ]
    }
  ]
}